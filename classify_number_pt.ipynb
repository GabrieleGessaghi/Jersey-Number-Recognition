{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoccerDataset(Dataset):\n",
    "    def __init__(self, images: List[str], targets: List[int], type: str ):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.n_samples = len(targets)\n",
    "        # Create a PyTorch trasnform that resizes the images and norn§alize it\n",
    "        if type == 'train':\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.Resize(size=(224, 224), antialias=True),\n",
    "                v2.RandomHorizontalFlip(p=0.5),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.Resize(size=(224, 224), antialias=True),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.Resize(size=(224, 224), antialias=True),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        unique_targets = set(self.targets)\n",
    "        self.targets2idx = {l: i for i, l in enumerate(unique_targets)}\n",
    "        self.idx2targets = {i: l for i, l in enumerate(unique_targets)}\n",
    "\n",
    "    def __getitem__(self, index: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img = read_image(self.images[index])\n",
    "        img = self.transforms(img)\n",
    "        target = self.targets[index]\n",
    "        target = torch.tensor(self.targets2idx[target], dtype=torch.long)\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"SoccerNet/jersey-2023/\"\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "test_path = os.path.join(dataset_path, 'test')\n",
    "train_images = glob.glob(os.path.join(train_path, 'images/**/*.jpg'), recursive=True)\n",
    "test_images = glob.glob(os.path.join(test_path, 'images/**/*.jpg'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import resize\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "train_gt = json.load(open(os.path.join(train_path, 'train_gt.json')))\n",
    "train_targets = []\n",
    "for id in os.listdir(os.path.join(train_path, 'images/')):\n",
    "    try:\n",
    "        int(id)\n",
    "        train_targets.extend([train_gt[id]] * len(os.listdir(os.path.join(train_path, 'images/', id))))\n",
    "    except Exception:\n",
    "        print(f\"Skipping {id}, succhiamelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = json.load(open(os.path.join(test_path, 'test_gt.json')))\n",
    "test_targets = []\n",
    "for id in os.listdir(os.path.join(test_path, 'images/')):\n",
    "    try:\n",
    "        int(id)\n",
    "        test_targets.extend([test_gt[id]] * len(os.listdir(os.path.join(test_path, 'images/', id))))\n",
    "    except Exception:\n",
    "        print(f\"Skipping {id}, succhiamelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "train_data = SoccerDataset(train_images, train_targets, 'train')\n",
    "test_data = SoccerDataset(test_images, test_targets, 'test')\n",
    "\n",
    "train_set_size = int(len(train_data) * 0.8)\n",
    "valid_set_size = len(train_data) - train_set_size\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = data.random_split(train_data, [train_set_size, valid_set_size], generator=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "# Assuming you have a class_labels tensor with the class labels for each sample\n",
    "# Replace this with your actual class labels\n",
    "class_labels = torch.tensor(train_targets)\n",
    "\n",
    "# Convert indices to integers\n",
    "train_indices = [int(idx) for idx in train_set.indices]\n",
    "valid_indices = [int(idx) for idx in valid_set.indices]\n",
    "\n",
    "# Get class labels for each set\n",
    "train_class_labels = class_labels[train_indices]\n",
    "valid_class_labels = class_labels[valid_indices]\n",
    "test_class_labels = torch.tensor(test_targets)\n",
    "\n",
    "for label in train_class_labels:\n",
    "    if label < 0:\n",
    "        train_class_labels[train_class_labels == label] = 99\n",
    "\n",
    "for label in valid_class_labels:\n",
    "    if label < 0:\n",
    "        valid_class_labels[valid_class_labels == label] = 99\n",
    "\n",
    "for label in test_class_labels:\n",
    "    if label < 0:\n",
    "        test_class_labels[test_class_labels == label] = 99\n",
    "\n",
    "# Count the occurrences of each class label in each set\n",
    "train_class_counts = torch.bincount(train_class_labels)\n",
    "valid_class_counts = torch.bincount(valid_class_labels)\n",
    "test_class_counts = torch.bincount(test_class_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funzione per dividere le classi in gruppi di n\n",
    "def split_classes(class_counts, n):\n",
    "    return [class_counts[i:i+n] for i in range(0, len(class_counts), n)]\n",
    "\n",
    "# Imposta la spaziatura tra le classi sull'asse x\n",
    "bar_spacing = 0.4  # Regola questo valore secondo le tue preferenze\n",
    "\n",
    "# Calcola le posizioni delle classi per ciascun set\n",
    "train_positions = np.arange(len(train_class_counts))\n",
    "valid_positions = np.arange(len(valid_class_counts))\n",
    "test_positions = np.arange(len(test_class_counts))\n",
    "\n",
    "# Divide le classi in 4 gruppi per ciascun set\n",
    "train_class_groups = split_classes(train_class_counts, len(train_class_counts)//4)\n",
    "valid_class_groups = split_classes(valid_class_counts, len(valid_class_counts)//4)\n",
    "test_class_groups = split_classes(test_class_counts, len(test_class_counts)//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_sum = sum(train_class_counts)\n",
    "for i, class_group in enumerate(train_class_groups):\n",
    "    normalized_values = [value / total_train_sum for value in class_group]\n",
    "    tick_labels = range(i * len(normalized_values), (i + 1) * len(normalized_values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(train_positions[:len(normalized_values)], class_group, tick_label=tick_labels)\n",
    "    plt.title(f'Class Distribution in Train Set - Group {i+1}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "\n",
    "    for bar, value in zip(bars, normalized_values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2%}', \n",
    "                 ha='center', va='bottom', fontsize=6)  # Regola la dimensione del font qui\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid_sum = sum(valid_class_counts)\n",
    "for i, class_group in enumerate(valid_class_groups):\n",
    "    normalized_values = [value / total_valid_sum for value in class_group]\n",
    "    tick_labels = range(i * len(normalized_values), (i + 1) * len(normalized_values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(valid_positions[:len(normalized_values)], class_group, tick_label=tick_labels)\n",
    "    plt.title(f'Class Distribution in Validation Set - Group {i+1}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "\n",
    "    for bar, value in zip(bars, normalized_values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2%}', \n",
    "                 ha='center', va='bottom', fontsize=6)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_sum = sum(test_class_counts)\n",
    "for i, class_group in enumerate(test_class_groups):\n",
    "    normalized_values = [value / total_test_sum for value in class_group]\n",
    "    tick_labels = range(i * len(normalized_values), (i + 1) * len(normalized_values))\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(test_positions[:len(normalized_values)], class_group, tick_label=tick_labels)\n",
    "    plt.title(f'Class Distribution in Test Set - Group {i+1}')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "\n",
    "    for bar, value in zip(bars, normalized_values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2%}', \n",
    "                 ha='center', va='bottom', fontsize=6)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoccerDataset(Dataset):\n",
    "    def __init__(self, images: List[str], targets: List[int], type: str ):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.n_samples = len(targets)\n",
    "        # Create a PyTorch trasnform that resizes the images and norn§alize it\n",
    "        if type == 'train':\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.Resize(size=(224, 224), antialias=True),\n",
    "                v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "                v2.RandomGrayscale(0.5),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = v2.Compose([\n",
    "                v2.Resize(size=(224, 224), antialias=True),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        unique_targets = set(self.targets)\n",
    "        self.targets2idx = {l: i for i, l in enumerate(unique_targets)}\n",
    "        self.idx2targets = {i: l for i, l in enumerate(unique_targets)}\n",
    "\n",
    "    def __getitem__(self, index: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img = read_image(self.images[index]) / 255.0\n",
    "        img = self.transforms(img)\n",
    "        target = self.targets[index]\n",
    "        target = torch.tensor(self.targets2idx[target], dtype=torch.long)\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_samples\n",
    "    \n",
    "class SoccerNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int ):\n",
    "        super().__init__()\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import lightning as L\n",
    "import torchmetrics\n",
    "\n",
    "class LitSoccerNet (L.LightningModule):\n",
    "    def __init__(self, net: SoccerNet, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.train_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.valid_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.net(images)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        accuracy = self.train_acc(logits, targets)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_accuracy\", accuracy, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=3e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.net(images)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        accuracy = self.test_acc(logits, targets)\n",
    "        self.log(\"test_accuracy\", accuracy, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        logits = self.net(images)\n",
    "        val_loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        accuracy = self.valid_acc(logits, targets)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_accuracy\", accuracy, on_epoch=True, on_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "class SoccerNetDataModule (L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train_path = os.path.join(self.data_dir, 'train')\n",
    "        self.test_path = os.path.join(self.data_dir, 'test')\n",
    "\n",
    "        self.train_images = glob.glob(os.path.join(self.train_path, 'images/**/*.jpg'), recursive=True)\n",
    "        self.test_images = glob.glob(os.path.join(self.test_path, 'images/**/*.jpg'), recursive=True)\n",
    "\n",
    "        train_gt = json.load(open(os.path.join(self.train_path, 'train_gt.json')))\n",
    "        self.train_targets = []\n",
    "        for id in os.listdir(os.path.join(self.train_path, 'images/')):\n",
    "            try:\n",
    "                int(id)\n",
    "                self.train_targets.extend([train_gt[id]] * len(os.listdir(os.path.join(self.train_path, 'images/', id))))\n",
    "            except Exception:\n",
    "                print(f\"Skipping {id}\")\n",
    "\n",
    "        test_gt = json.load(open(os.path.join(self.test_path, 'test_gt.json')))\n",
    "        self.test_targets = []\n",
    "        for id in os.listdir(os.path.join(self.test_path, 'images/')):\n",
    "            try:\n",
    "                int(id)\n",
    "                self.test_targets.extend([test_gt[id]] * len(os.listdir(os.path.join(self.test_path, 'images/', id))))\n",
    "            except Exception:\n",
    "                print(f\"Skipping {id}\")\n",
    "        \n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_data = SoccerDataset(self.train_images, self.train_targets, type='train')\n",
    "            self.idx2targets = train_data.idx2targets\n",
    "            self.targets2idx = train_data.targets2idx\n",
    "            train_set_size = int(len(train_data) * 0.8)\n",
    "            valid_set_size = len(train_data) - train_set_size\n",
    "            seed = torch.Generator().manual_seed(42)\n",
    "            train_set, valid_set = random_split(train_data, [train_set_size, valid_set_size], generator=seed)\n",
    "            self.train_set = train_set\n",
    "            self.valid_set = valid_set\n",
    "        \n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_data = SoccerDataset(self.test_images, self.test_targets, type='test')\n",
    "            self.test_set = test_data\n",
    "\n",
    "        if stage == \"predict\" or stage is None:\n",
    "            pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_set, batch_size=self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "DATASET_PATH = \"SoccerNet/jersey-2023/\"\n",
    "NUM_CLASSES = 45 #len(train_data.targets2idx)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "net = SoccerNet(num_classes=NUM_CLASSES)\n",
    "autoSoccerNet = LitSoccerNet(net, NUM_CLASSES)\n",
    "data_module = SoccerNetDataModule(DATASET_PATH, BATCH_SIZE)\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_accuracy',\n",
    "    filename='SoccerNet-{val_accuracy:.2f}-{val_loss:.2f}',\n",
    "    verbose=True,\n",
    "    dirpath='checkpointsV3/',\n",
    "    every_n_train_steps=3000,\n",
    "    enable_version_counter=True,\n",
    "    save_top_k=-1\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    enable_checkpointing=True, \n",
    "    callbacks=[checkpoint_callback],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "trainer.fit(autoSoccerNet, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "checkpoint = 'checkpoints/SoccerNet-train_accuracy=1.00-train_loss=0.02.ckpt'\n",
    "autoSoccerNet = LitSoccerNet.load_from_checkpoint(checkpoint, net=net, num_classes=NUM_CLASSES,strict=False)\n",
    "\n",
    "classifier = autoSoccerNet.net\n",
    "classifier.eval()\n",
    "\n",
    "# Move the classifier to the same device as your input data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "\n",
    "image = load_img('test.jpg')\n",
    "image = img_to_array(image) / 255.0\n",
    "torch_image = torch.from_numpy(image)\n",
    "torch_image = torch_image.unsqueeze(0).permute(0,3,1,2)\n",
    "transform = transforms.Compose([\n",
    "    v2.Resize(size=(224, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    v2.Grayscale(num_output_channels=3)\n",
    "])\n",
    "\n",
    "input_img = transform(torch_image)\n",
    "\n",
    "preds = classifier(input_img)\n",
    "print(preds.softmax(-1).argmax(1))\n",
    "print(f\"Most likely class: {data_module.idx2targets[torch.argmax(preds).item()]}\")\n",
    "\n",
    "plt.imshow(input_img.squeeze().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST THE MODEL PERFORMANCE ON THE TEST SET WITH 3 IMAGES PER FOLDER, PRINTING THE NUMBER OF CORRECTLY IDENTIFIED JERSEYS\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import  tqdm\n",
    "\n",
    "MODEL_CHECKPOINT = 'checkpointsV3/SoccerNet-train_accuracy=1.00-train_loss=0.01.ckpt'\n",
    "autoSoccerNet = LitSoccerNet.load_from_checkpoint(MODEL_CHECKPOINT, net=net, num_classes=NUM_CLASSES,strict=False)\n",
    "\n",
    "classifier = autoSoccerNet.net\n",
    "classifier.eval()\n",
    "\n",
    "# Move the classifier to the same device as your input data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "classifier = classifier.to('cpu')\n",
    "test_path = 'SoccerNet/jersey-2023/test/'\n",
    "test_gt = json.load(open(os.path.join(test_path, 'test_gt.json')))\n",
    "total_correct = 0\n",
    "total_images = 0\n",
    "\n",
    "for id in tqdm(os.listdir(os.path.join(test_path, 'images/')), desc= 'Testiing ...'):\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    for image in os.listdir(os.path.join(test_path, 'images/', id)):\n",
    "        image_path = os.path.join(test_path, 'images/', id, image)\n",
    "        image = load_img(image_path)\n",
    "        image = img_to_array(image) / 255.0\n",
    "        torch_image = torch.from_numpy(image)\n",
    "        torch_image = torch_image.unsqueeze(0).permute(0,3,1,2)\n",
    "        transform = transforms.Compose([\n",
    "            v2.Resize(size=(224, 224), antialias=True),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            #v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            v2.Grayscale(3),\n",
    "            \n",
    "        ])\n",
    "\n",
    "        input_img = transform(torch_image)\n",
    "        input_img.to(device)\n",
    "\n",
    "        preds = classifier(input_img)\n",
    "        predicted_class =  data_module.idx2targets[torch.argmax(preds).item()]\n",
    "        real_class = test_gt[id]\n",
    "        print(f'Real class {real_class}, Predcited class {predicted_class}')\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "            total_correct += 1\n",
    "\n",
    "        counter += 1\n",
    "        total_images += 1\n",
    "        if counter == 10:\n",
    "            print(f'Number correctly identified for {id} with real class {real_class} : {correct}/10')\n",
    "            print('------------------------------------------------------------------------------------------------')\n",
    "            break\n",
    "\n",
    "\n",
    "print(f'Total corrected predictions: {total_correct}/{total_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
